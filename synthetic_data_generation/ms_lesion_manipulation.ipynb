{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import monai\n",
    "import os \n",
    "import numpy as np\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import scipy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from monai.data import create_test_image_3d, list_data_collate, decollate_batch, partition_dataset, DatasetSummary\n",
    "from monai.transforms import (Activationsd,AdjustContrastd,AsDiscrete,Compose,LoadImaged,LabelFilter,Invertd,EnsureTyped,AddChanneld,SaveImaged)\n",
    "from itertools import cycle\n",
    "\n",
    "sys.path.append('..')\n",
    "from utilities import get_split_deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data directory and filenames and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir ='/path/data/*' # in-house dataset\n",
    "source_exams = glob.glob(root_dir)\n",
    "patients = set([os.path.split(exam)[-1].split('_')[0] for exam in source_exams])\n",
    "fold = 0\n",
    "train,val = get_split_deterministic(patients,fold=fold, num_splits=5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_seg1 = 'segmentation_1.nii.gz' # MS lesion segmentation baseline \n",
    "file_name_flair = 'FLAIR_1.nii.gz' # FLAIR baseline\n",
    "file_name_t1 = 'T1_1.nii.gz' # T1 baseline \n",
    "file_name_brain_seg = 'brain_1_seg.nii.gz' # brain segmentation\n",
    "\n",
    "source_pool = cycle(source_exams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cycle through exams in the training dataset and copy files to OASIS exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_dir = '/path/oasis/data/' \n",
    "source_patients = []\n",
    "for exam in os.listdir(dest_dir):\n",
    "    dest_path = os.path.join(dest_dir,exam)\n",
    "    \n",
    "    while 'FLAIR_1.nii.gz' not in os.listdir(dest_path):  #check if the source flair images have been copied to all folders in dest\n",
    "        path = next(source_pool)\n",
    "        source_patient =os.path.split(path)[-1].split('_')[0] # extract patient id\n",
    "        if source_patient in val:\n",
    "            print(source_patient, ' Scan not copied to destintaion, patient belongs to validation group.')\n",
    "            pass\n",
    "        else:\n",
    "            print(dest_path, source_patient)\n",
    "            source_patients.append(source_patient)\n",
    "            if source_patients.count(source_patient) > 2: # ensure same source is not used more than 2 times\n",
    "                print(source_patient, 'Enough samples')\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                t1_path = os.path.join(path,file_name_t1)\n",
    "                assert os.path.exists(t1_path)\n",
    "                shutil.copy(t1_path, dest_path)\n",
    "\n",
    "                flair_path = os.path.join(path,file_name_flair)\n",
    "                assert os.path.exists(flair_path)\n",
    "                shutil.copy(flair_path, dest_path)\n",
    "\n",
    "                seg_path = os.path.join(path,file_name_seg1)\n",
    "                assert os.path.exists(seg_path)\n",
    "                shutil.copy(seg_path, dest_path)\n",
    "\n",
    "                seg_path = os.path.join(path,file_name_brain_seg)\n",
    "                assert os.path.exists(seg_path)\n",
    "                shutil.copy(seg_path, dest_path)            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of baseline and follow-up lesions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "root_dir = '/path/data'\n",
    "file_name_seg1 = 'segmentation_1.nii.gz' # baseline MS lesion segmentation\n",
    "file_name_seg2 = 'segmentation_2.nii.gz' # follow up MS lesions segmentation\n",
    "\n",
    "patient_lesion_details = []\n",
    "\n",
    "for exam in os.listdir(root_dir):\n",
    "    dest_path = os.path.join(root_dir,exam)\n",
    "    seg1 = nib.load(os.path.join(dest_path,file_name_seg1)).get_fdata() # load lesion segmentation_1\n",
    "    label_array, num_features_1 = scipy.ndimage.label(seg1) #generate distinct labels and find number of lesions\n",
    "    \n",
    "    seg2 = nib.load(os.path.join(dest_path,file_name_seg2)).get_fdata() # load lesion segmentation_1\n",
    "    label_array, num_features_2 = scipy.ndimage.label(seg2) #generate distinct labels and find number of lesions\n",
    "    \n",
    "    exam_details = {'exam':exam, 'lesion_count_baseline':num_features_1, 'lesion_count_follow_up':num_features_2}\n",
    "    patient_lesion_details.append(exam_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_df = pd.DataFrame(patient_lesion_details)\n",
    "lesion_df['lesion_comparison'] = lesion_df['lesion_count_baseline'] - lesion_df['lesion_count_follow_up']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(lesion_df, x=\"lesion_count_baseline\", y=\"lesion_count_follow_up\",cbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulate lesion segmentation maps to create balanced dataset\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dest_dir = '/path/oasis/data/'\n",
    "file_name_seg1 = 'segmentation_1.nii.gz'\n",
    "\n",
    "oasis_details = []\n",
    "index = 0\n",
    "\n",
    "for exam in sorted(os.listdir(dest_dir)):\n",
    "    index+=1\n",
    "    dest_path = os.path.join(dest_dir,exam)\n",
    "    seg1 = nib.load(os.path.join(dest_path,file_name_seg1)) # load lesion segmentation_1\n",
    "    seg1_vol = seg1.get_fdata()\n",
    "    header = seg1.header.copy()\n",
    "    label_array, num_features = scipy.ndimage.label(seg1_vol) #generate distinct labels and find number of lesions\n",
    "    if index%2 ==0:\n",
    "        num_eliminate =  int(0.8*num_features)\n",
    "        filtered_array = LabelFilter(applied_labels=random.sample(list(np.arange(1,num_features)), num_eliminate))(label_array)\n",
    "        filtered_nifti = nib.Nifti1Image(filtered_array, None,header=header)\n",
    "        nib.save(filtered_nifti, os.path.join(dest_path, 'lesion_seg_oasis_bl.nii.gz'))\n",
    "        exam_details = {'exam':exam, 'lesion_count_baseline':num_features, 'lesion_count_follow_up':num_eliminate, 'change':1}\n",
    "    else:\n",
    "        exam_details = {'exam':exam, 'lesion_count_baseline':num_features, 'lesion_count_follow_up':num_features, 'change':0}\n",
    "        nib.save(seg1, os.path.join(dest_path, 'lesion_seg_oasis_bl.nii.gz'))\n",
    "    oasis_details.append(exam_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save lesion count data for exam pairs as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oasis_df = pd.DataFrame(oasis_details)\n",
    "oasis_df.to_csv('/path/oasis/oasis_lesion_labels_fold.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
