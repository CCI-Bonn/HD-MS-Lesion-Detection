{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import monai\n",
    "from monai.data import list_data_collate, decollate_batch, partition_dataset, DatasetSummary\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    AsChannelLastd,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    ConcatItemsd,\n",
    "    LoadImaged,\n",
    "    RandRotated,\n",
    "    EnsureTyped,\n",
    "    AddChanneld,\n",
    "    CropForegroundd,\n",
    "    EnsureType,\n",
    "    Spacingd,\n",
    "    CenterSpatialCropd,\n",
    "    SpatialPadd,\n",
    "    ScaleIntensityRanged,\n",
    "    SqueezeDimd,\n",
    "    ScaleIntensityd,\n",
    "    NormalizeIntensityd\n",
    ")\n",
    "from monai.inferers import SimpleInferer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data directory and filenames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir ='/path/oasis/data/'\n",
    "\n",
    "file_name_img = 'T1_oasis_reg.nii.gz' # co-registered T1 image from OASIS dataset\n",
    "file_name_seg = 'brain_lesion_oasis_fu.nii.gz'# merged segmentation map\n",
    "\n",
    "all_patients = os.listdir(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read image filenames for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = [os.path.join(root_dir,i,file_name_img) for i in all_patients]\n",
    "test_segs = [os.path.join(root_dir,i,file_name_seg) for i in all_patients]\n",
    "test_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(test_images, test_segs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the transformations to be applied on the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = Compose(\n",
    "    [   LoadImaged(keys=['img','seg'], reader='ITKReader'),\n",
    "         AddChanneld(keys=['img','seg'],),\n",
    "         Spacingd(keys=['img','seg'],pixdim=(0.8,1), mode=['bilinear', 'nearest']),\n",
    "         CropForegroundd(keys=['img','seg'],source_key='seg', margin=10),\n",
    "         CenterSpatialCropd(keys=['img','seg'],roi_size =(192,240,160)),\n",
    "         SpatialPadd(keys=['img','seg'],spatial_size=(192,240,160)),\n",
    "         NormalizeIntensityd(keys=['img']),\n",
    "         ScaleIntensityRanged(keys='seg', a_min=0, a_max=5, b_min=0, b_max=1),\n",
    "         ConcatItemsd(keys=['img','seg'],name='input'),\n",
    "         EnsureTyped(keys=['img','seg']),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = monai.data.Dataset(data=test_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=2, num_workers=4, collate_fn=list_data_collate)\n",
    "test_loader_iter = iter(test_loader) # create iterable object for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(train_loader_iter)\n",
    "img, seg = batch['img'], batch['seg']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "for j in range(2):\n",
    "        plt.subplot(2, 4, j + 1)\n",
    "        plt.imshow(img[j,0,:, :, 90], cmap=\"gray\")\n",
    "        \n",
    "        plt.subplot(2, 4, j + 5)\n",
    "        plt.imshow(seg[j,0,:, :, 90], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network and load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = monai.networks.nets.UNet( \n",
    "    spatial_dims=3,\n",
    "    in_channels=2,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2)\n",
    ").to(device)\n",
    "\n",
    "generator.load_state_dict(torch.load(\"./models/generator.pth\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define transforms for postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_transforms = Compose([\n",
    "    Invertd(\n",
    "        keys=\"pred\",  # invert the `pred` data field, also support multiple fields\n",
    "        transform=test_transforms,\n",
    "        orig_keys=\"img\",  # get the previously applied pre_transforms information on the `img` data field,\n",
    "                          # then invert `pred` based on this information. we can use same info\n",
    "                          \n",
    "        meta_keys=\"pred_meta_dict\",  # key field to save inverted meta data, every item maps to `keys`\n",
    "        orig_meta_keys=\"img_meta_dict\",  # get the meta data from `img_meta_dict` field when inverting,\n",
    "                                         \n",
    "                                        \n",
    "        meta_key_postfix=\"meta_dict\",  # if `meta_keys=None`, use \"{keys}_{meta_key_postfix}\" as the meta key,\n",
    "                                       \n",
    "                                       \n",
    "        nearest_interp=False,  \n",
    "                               \n",
    "        to_tensor=True,  # convert to PyTorch Tensor after inverting\n",
    "    ),\n",
    "    SaveImaged(keys=\"pred\", meta_keys=\"pred_meta_dict\", output_dir=\"/path/oasis/predictions/\", data_root_dir= '/path/oasis/data',output_postfix=\"mc_fu_syn\", separate_folder=False, resample=False),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inf = SimpleInferer()\n",
    "with torch.no_grad():\n",
    "    for d in test_loader:\n",
    "        seg = d[\"input\"].to(device)\n",
    "        # define sliding window size and batch size for windows inference\n",
    "        d[\"pred\"] = inf(inputs=seg, network=generator)\n",
    "        # decollate the batch data into a list of dictionaries, then execute postprocessing transforms\n",
    "        d = [post_transforms(i) for i in decollate_batch(d)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
